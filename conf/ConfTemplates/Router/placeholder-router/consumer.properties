bootstrap.servers=[BOOTSTRAP_SERVER_PLACEHOLDER]

# key as string, value as ByteArray
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer

group.id=placeholder-router-consumer-group
client.id=placeholder-router-consumer-client

#auto commit is not allowed
enable.auto.commit=false
auto.commit.interval.ms=1000


# The size of the TCP receive buffer (SO_RCVBUF) to use when reading data.
# default 65536
# receive.buffer.bytes=65536

# 10M This size must be at least as large as the maximum message size the server allows
# or else it is possible for the producer to send messages larger than the consumer can fetch.
max.partition.fetch.bytes=10485760


# set max poll record as 30 records. 30 * 10 = 300 MB
max.poll.records=30

session.timeout.ms=30000

# These buffer sizes seem to be needed to avoid consumer switching to
# a mode where it processes one bufferful every 5 seconds with multiple
# timeouts along the way.  No idea why this happens.
##fetch.min.bytes=50000